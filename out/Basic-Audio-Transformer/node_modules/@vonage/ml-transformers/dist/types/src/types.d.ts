import { Results as FaceDetectionResults, Options as FaceDetectionOptions } from '@mediapipe/face_detection';
import { Results as FaceMeshResults, Options as FaceMeshOptions } from '@mediapipe/face_mesh';
import { Results as HandsResults, Options as HandsOptions } from '@mediapipe/hands';
import { Results as HolisticResults, Options as HolisticOptions } from '@mediapipe/holistic';
import { Results as ObjectronResults, Options as ObjectronOptions } from '@mediapipe/objectron';
import { Results as SelfieSegmentationResults, Options as SelfieSegmentationOptions } from '@mediapipe/selfie_segmentation';
import { Results as PoseResults, Options as PoseOptions } from '@mediapipe/pose';
/**
 * VonageTransformerType which type of transformer to create.
 */
export declare type VonageTransformerType = 'BackgroundBlur' | 'VirtualBackground' | 'VideoBackground' | 'SilueteBlur';
/**
 * BlurRadius specifies how much bluring filter to apply by a given transformer.
 * @Low - 5px blur
 * @High - 10px blur
 */
export declare enum BlurRadius {
    /**
     * Low bluring filtering.
     */
    Low = "Low",
    /**
     * High bluring filtering.
     */
    High = "High"
}
/**
* MediaProcessorBaseConfig specifies the absolute URL for the path where the mediapipe assets used by the transformers from this library are stored.
* Vonage hosts static assets of mediapipe that will be used in case this property is not set.
* Vonage promises to take care of maintaining all versioning.
*
* @example
*
* ```ts
* {
*   mediapipeBaseAssetsUri: 'http://localhost:8080/assets' | undeifined
* }
* ```
* mediapipeBaseAssetsUri - should be the uri path to mediapipe assets.
* *** WARNING *** - using this option moves the responsibility of the assets and the versioning to the user.
* mediapipe selfie segmintaion got those assets:
* selfie_segmentation_landscape.tflite
* selfie_segmentation_solution_simd_wasm_bin.js
* selfie_segmentation_solution_simd_wasm_bin.wasm
* selfie_segmentation_solution_wasm_bin.js
* selfie_segmentation_solution_wasm_bin.wasm
* selfie_segmentation.binarypb
* selfie_segmentation.tflite
* please keep in mind that the assets list can change between versions!
* all assets can be taken from `node_modules/@mediapipe/selfie_segmentation`
*/
export declare type MediaProcessorBaseConfig = {
    mediapipeBaseAssetsUri?: string;
};
/**
 * BackgroundBlurConfig specifies the configuration for a transformer logic that performs background blurring.
 * @radius - @BlurRadius or number indicating the blur radius.
 * ```ts
 * let blurConfig: BackgroundBlurConfig = {
 *  transformerType: 'BackgroundBlur',
 *  radius: 8
 * }
 * // ..
 * ctx.filter = 'blur(8px)'
 * ```
 */
export declare type BackgroundBlurConfig = {
    transformerType: 'BackgroundBlur';
    radius?: BlurRadius | number;
};
/**
 * AssetBackgroundConfig specifies the absolute URL to the image or video file used for background replacement.
 */
export declare type AssetBackgroundConfig = {
    backgroundAssetUri: string;
};
/**
 * VirtualBackgroundConfig specifies the configuration for a transformer logic that performs background replacement with a given image.
 */
export declare type VirtualBackgroundConfig = {
    transformerType: 'VirtualBackground';
};
/**
 * VirtualBackgroundConfig specifies the configuration for a transformer logic that performs background replacement with a given video.
 */
export declare type VideoBackgroundConfig = {
    transformerType: 'VideoBackground';
};
/**
 * BackgroundBlurConfig specifies the configuration for a transformer logic that performs siluete blurring.
 */
export declare type SilueteBlurConfig = {
    transformerType: 'SilueteBlur';
    radius?: BlurRadius;
};
export type { FaceDetectionResults, FaceDetectionOptions, FaceMeshResults, FaceMeshOptions, HandsResults, HandsOptions, HolisticResults, HolisticOptions, ObjectronResults, ObjectronOptions, SelfieSegmentationResults, SelfieSegmentationOptions, PoseResults, PoseOptions };
/**
 * MediaPipeResults types of results object of MediaPipe
 */
export declare type MediaPipeResults = FaceDetectionResults | FaceMeshResults | HandsResults | HolisticResults | ObjectronResults | SelfieSegmentationResults | PoseResults;
/**
 * ResultsListener callback function from MediaPipe process
 * @results - The results object from MediaPipe
 * @returns - can return a promise of void
 */
export declare type MediaPipeResultsListener = <T extends MediaPipeResults>(results: T) => (Promise<void> | void);
/**
 * MediaPipeModelType supported models types
 */
export declare type MediaPipeModelType = "face_mesh" | "face_detection" | "hands" | "holistic" | "objectron" | "selfie_segmentation" | "pose";
/**
 * defines one mediapipe model config
 * @modelType - which model is required
 * @listener - callback function from the model
 * @options - define options for the mediapipe model that is used. for more info check https://google.github.io/mediapipe/getting_started/javascript.html
 * @assetsUri (optional) - can be set to get wasm/tflite/js/binarypb assets. Vonage provides static assets.
 * *** WARNING *** - using this option moves the responsibility of the assets and the versioning to the user.
 * please keep in mind that the assets list can change between versions!
 * assets are different between mediapipe models.
 */
export declare type MediaPipeModelConfig = {
    modelType: MediaPipeModelType;
    listener: MediaPipeResultsListener;
    options: FaceDetectionOptions | FaceMeshOptions | HandsOptions | HolisticOptions | ObjectronOptions | SelfieSegmentationOptions | PoseOptions;
    assetsUri?: string;
};
/**
 * MediapipeConfig specified config of mediapipe helper:
 * this structure allows the user to create few mediapipe models that will run in parallel.
 * @modelTypesArray - array of mediapipe models to be loaded and called.
 */
export declare type MediapipeConfig = {
    mediaPipeModelConfigArray: Array<MediaPipeModelConfig>;
};
